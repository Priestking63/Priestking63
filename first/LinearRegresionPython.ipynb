{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "s = string.ascii_lowercase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyLineReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg:\n",
    "\n",
    "\n",
    "    def __init__(self,learning_rate, sgd_sample = None, n_iter=100, weights=None, metric = None, reg:str = None, l1_coef = 0, l2_coef = 0, random_state = 42):\n",
    "\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l1_coef\n",
    "        self.reg = reg\n",
    "        self.random_state = random_state\n",
    "        self.sgd_sample = sgd_sample\n",
    "        \n",
    "    @staticmethod\n",
    "    def _l1(l1_coef ,l2_coef ,weights):\n",
    "        l2_coef = 0\n",
    "        reg_loss = l1_coef* np.sum(np.abs(weights))\n",
    "        reg_grad = l1_coef * np.sign(weights)\n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    @staticmethod\n",
    "    def _l2(l1_coef,l2_coef,weights):\n",
    "        l1_coef = 0\n",
    "        reg_loss = l2_coef * np.sum(weights**2)\n",
    "        reg_grad = l2_coef * np.dot(weights,2)\n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    @staticmethod\n",
    "    def _elasticnet(l1_coef, l2_coef, weights):\n",
    "        reg_loss = l1_coef* np.sum(np.abs(weights)) + l2_coef* np.sum(weights**2)\n",
    "        reg_grad = l1_coef * np.sign(weights) + l2_coef * (2*weights)\n",
    "        return reg_loss, reg_grad\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}\"\n",
    "\n",
    "\n",
    "    def fit(self, X_df: pd.DataFrame, Y_target: pd.Series, verbose=False):\n",
    "        random.seed(self.random_state)\n",
    "        self.X_df = X_df.insert(0, 'w0', 1)\n",
    "        n_features = X_df.shape[1]\n",
    "        self.weights = np.ones(n_features)\n",
    "        reg_loss, reg_grad = 0, 0\n",
    "        if self.sgd_sample == None:\n",
    "            self.sgd_sample = X_df.shape[0]\n",
    "        elif isinstance(self.sgd_sample, float):\n",
    "            self.sgd_sample = round(X_df.shape[0] * self.sgd_sample)\n",
    "        for i in range(1,self.n_iter+1):\n",
    "            if callable(self.learning_rate):\n",
    "                learning_r = self.learning_rate(i)\n",
    "            else:\n",
    "                learning_r = self.learning_rate\n",
    "            if self.reg:\n",
    "                reg_loss, reg_grad = getattr(self, '_' + self.reg)(self.l1_coef,self.l2_coef,self.weights)\n",
    "            sample_rows_idx = random.sample(range(X_df.shape[0]), self.sgd_sample)\n",
    "            y_pred = np.dot(X_df.iloc[sample_rows_idx], self.weights)          \n",
    "            MSE = np.mean((Y_target - np.dot(X_df, self.weights))**2) + reg_loss\n",
    "            gradient = 2/X_df.iloc[sample_rows_idx].shape[0] * np.dot(X_df.iloc[sample_rows_idx].T, (y_pred - Y_target.iloc[sample_rows_idx])) + reg_grad\n",
    "            self.weights -= learning_r * gradient\n",
    "            y_pred = self.weights @ X_df.T\n",
    "            result_metric = self.calculate_metric(Y_target, y_pred)\n",
    "            if verbose:\n",
    "                if i%verbose:\n",
    "                     logging.info(f\"{i} | loss: {sum(MSE)}| {self.metric}:{result_metric}\")\n",
    "            \n",
    "    def calculate_metric(self, y, y_hat):\n",
    "        if self.metric == 'mae':\n",
    "            return np.mean(np.abs(y - y_hat))\n",
    "        elif self.metric == 'mse':\n",
    "            return np.mean((y - y_hat) ** 2)\n",
    "        elif self.metric == 'rmse':\n",
    "            return np.sqrt(np.mean((y - y_hat) ** 2))\n",
    "        elif self.metric == 'mape':\n",
    "            return 100 * np.mean(np.abs((y - y_hat) / y))\n",
    "        elif self.metric == 'r2':\n",
    "            total_variance = np.sum((y - np.mean(y))**2)\n",
    "            return 1 - np.sum((y - y_hat)**2) / total_variance\n",
    "        return None\n",
    "    \n",
    "    def get_best_score(self):\n",
    "        return self.result_metric\n",
    "\n",
    "\n",
    "    def get_coef(self):\n",
    "            return self.weights[1:] \n",
    "            \n",
    "    def predict(self, X_df):\n",
    "        X_df.insert(0, 'w0', 1)\n",
    "        y_pred = np.dot(X_df, self.weights)\n",
    "        return y_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
