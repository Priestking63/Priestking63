import sqlite3 
import numpy as np
import logging
from typing import List, Dict, Any
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from transform import TextEmbedder

logging.basicConfig(level= logging.INFO)
logger = logging.getLogger(__name__)

class SmartTelegramAssistant():
    def __init__(self, db = 'bot_base.db', similarity_threshold = 0.7):
        self.db_path = db
        self.threshold = similarity_threshold

        self.embedder = TextEmbedder()

        self.generator = pipeline(
            "text2text-generation",
            model="IlyaGusev/rut5_base_sum_gazeta",
            tokenizer="IlyaGusev/rut5_base_sum_gazeta",
            max_length=200,
        )
        self.init_db()
    def init_db(self):
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute(
            """
            SELECT name FROM sqlite_master 
            WHERE type='table' AND name='skidki'
        """
        )

    def cosine_similarity(self, vec1: bytes, vec2: bytes):
        vec1 = np.frombuffer(vec1, dtype=np.float32)
        vec2 = np.frombuffer(vec2, dtype=np.float32)
        dot_product = vec1@vec2
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        if norm1 == 0 or norm2 == 0:
            return 0
        sim = float(dot_product/(norm1*norm2))
        return max(0.0, min(1.0, sim))

    def search_similar_mes(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        query_embedding_blob = self.embedder.get_embeddings(query)
        if query_embedding_blob is None:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —ç–º–±–µ–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
            return []
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT message_id, channel, date, text, embedding FROM skidki WHERE embedding IS NOT NULL")
        message = cursor.fetchall()
        conn.close()

        similarities = []
        for mes in message:
            message_id, channel, date, text, embedding = mes
            if not embedding:
                continue
            score = self.cosine_similarity(query_embedding_blob, embedding)
            if score > self.threshold:
                similarities.append({'message_id': message_id,
                                     'channel':channel,
                                     'date': date,
                                     'text': text,
                                     'similarity': score})

        similarities.sort(key = lambda x: x["similarity"], reverse=True)

        return similarities[:top_k]

    def generate_ai_response(self, query: str, context_message: List[Dict[str, Any]]):
        if not context_message:
            return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª –ø–æ–¥—Ö–æ–¥—è—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö."

        if self.generator is None:
            return self._generate_simple_response(context_message)

        context = " | ".join([msg["text"] for msg in context_message[:3]])
        prompt = f"–í–æ–ø—Ä–æ—Å: {query} –ö–æ–Ω—Ç–µ–∫—Å—Ç: {context} –û—Ç–≤–µ—Ç:"

        return self.generator(prompt, max_length = 150, do_sample = True, temperature = 0.7)

    def _generate_simple_response(self, messages: List[Dict[str, Any]]) -> str:
        best_match = messages[0] if messages else None
        if best_match:
            return f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É —è –Ω–∞—à–µ–ª:\n\n{best_match['text']}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {best_match['channel']}"
        return "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–∞."

    def format_similar_messages_response(self, similar_messages: List[Dict[str, Any]]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç"""
        if not similar_messages:
            return "‚ùå –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."

        response = "üîç **–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ—Ö–æ–∂–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:**\n\n"

        for i, msg in enumerate(similar_messages, 1):
            response += f"**{i}. –ö–∞–Ω–∞–ª:** {msg['channel']}\n"
            response += f"**–î–∞—Ç–∞:** {msg['date']}\n"
            response += f"**–°—Ö–æ–¥—Å—Ç–≤–æ:** {msg['similarity']:.2%}\n"
            response += f"**–¢–µ–∫—Å—Ç:** {msg['text']}\n"
            response += "‚îÄ" * 50 + "\n\n"

        return response

    def response(self, query: str, top_k: int = 5, use_ai: bool = False) -> str:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å"""
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {query}")

        similar_messages = self.search_similar_mes(query, top_k)

        if use_ai and self.generator and similar_messages:
            context = " | ".join([msg["text"] for msg in similar_messages[:3]])
            prompt = (
                f"–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {context} –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: {query}"
            )

            try:
                ai_response = self.generator(
                    prompt, max_length=150, do_sample=True, temperature=0.7
                )
                if ai_response and len(ai_response) > 0:
                    generated_text = ai_response[0]["generated_text"]

                    response = "ü§ñ **AI-–æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:**\n\n"
                    response += f"{generated_text}\n\n"
                    response += "‚îÄ" * 50 + "\n\n"
                    response += self.format_similar_messages_response(similar_messages)
                    return response
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ AI-–æ—Ç–≤–µ—Ç–∞: {e}")
                return self.format_similar_messages_response(similar_messages)

        return self.format_similar_messages_response(similar_messages)


if __name__ == "__main__":
    assistant = SmartTelegramAssistant()

    print("ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –∑–∞–ø—É—â–µ–Ω! –ó–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã –æ —Å–∫–∏–¥–∫–∞—Ö –∏ –∞–∫—Ü–∏—è—Ö.")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:")
    print("- 'ai on' - –≤–∫–ª—é—á–∏—Ç—å AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤")
    print("- 'ai off' - –≤—ã–∫–ª—é—á–∏—Ç—å AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤")
    print("- 'exit' - –≤—ã—Ö–æ–¥\n")

    use_ai = False

    while True:
        try:
            query = input("\nüßê –í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()

            if query.lower() in ["exit", "–≤—ã—Ö–æ–¥", "quit"]:
                break
            elif query.lower() == "ai on":
                use_ai = True
                print("‚úÖ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –≤–∫–ª—é—á–µ–Ω–∞")
                continue
            elif query.lower() == "ai off":
                use_ai = False
                print("‚ùå AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –≤—ã–∫–ª—é—á–µ–Ω–∞")
                continue

            if query:
                response = assistant.response(query, use_ai=use_ai)
                print(f"\n{response}")

        except KeyboardInterrupt:
            print("\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
            break
        except Exception as e:
            print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
